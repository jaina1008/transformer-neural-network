{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "\n",
    "random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "\n",
    "# Mock positioning encoding of input sequence length.\n",
    "x = torch.randn(\n",
    "    (batch_size, sequence_length, input_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to create a concatenated vector of Query, Key and Value (QKV)\n",
    "qkv_layer = nn.Linear(input_dim, 3 * d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the tensor in equal parts for each multi-head attention unit.\n",
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the tensor so that batch processing can happen conveniently over the last two dimensions.\n",
    "qkv = qkv.permute(0, 2, 1, 3)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividing the tensor into Q,K,V\n",
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention for multiple heads\n",
    "\n",
    "<!-- For single head:\n",
    "$$\n",
    "self attention = text\\(softmax\\)\\({Q.K^T}/{sqrt{d_k}} + M\\)\n",
    "$$ -->\n",
    "$$\n",
    "\\text{Self-Attention} = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}} + M\\right)\n",
    "$$\n",
    "$$\n",
    "\\text{new V = self attention. V}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '-inf' and zero are used for mask because when we softmax, the exp('-inf') = 0 and exp(0) = 1\n",
    "mask = torch.full(scaled.size(), float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0104,    -inf,    -inf,    -inf],\n",
       "        [ 0.4573,  0.3351,    -inf,    -inf],\n",
       "        [ 0.1266,  0.1900,  0.3968,    -inf],\n",
       "        [-0.4235,  0.2646,  0.1196, -0.1123]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5305, 0.4695, 0.0000, 0.0000],\n",
       "        [0.2962, 0.3156, 0.3881, 0.0000],\n",
       "        [0.1646, 0.3275, 0.2833, 0.2247]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5305, 0.4695, 0.0000, 0.0000],\n",
       "        [0.2962, 0.3156, 0.3881, 0.0000],\n",
       "        [0.1646, 0.3275, 0.2833, 0.2247]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1270,  0.3230,  0.4618,  ...,  0.1667, -0.0873, -0.2934],\n",
       "         [-0.1133, -0.0123,  0.2438,  ...,  0.1674,  0.2670,  0.2090],\n",
       "         [-0.1077, -0.2198, -0.2461,  ...,  0.1936,  0.6056, -0.0764],\n",
       "         [-0.2263, -0.0193,  0.0655,  ...,  0.1329,  0.0734,  0.4772]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class\n",
    "\n",
    "Combining all of the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn(\n",
    "    (batch_size, sequence_length, input_dim)\n",
    ")\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
